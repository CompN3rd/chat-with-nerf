{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chat_with_nerf.chat.agent import Agent \n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from chat_with_nerf.chat.session import Session\n",
    "import time\n",
    "import open3d as o3d\n",
    "from pathlib import Path\n",
    "from chat_with_nerf.chat.system_prompt import EDITED_SYSTEM_PROMPT, NO_VISUAL_FEEDBACK_SYSTEM_PROMPT\n",
    "from chat_with_nerf.settings import Settings\n",
    "from joblib import Parallel, delayed\n",
    "from evaluation_vis_util import draw_plotly, create_bbox\n",
    "from tqdm import tqdm\n",
    "import uuid\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from utils import box3d_iou, process_json, process_all_json_files, is_label_unique, convert_origin_bbox, get_transformation_matrix, construct_bbox_corners, get_box3d_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT35\n",
    "# os.environ['API_URL'] = \"\"\n",
    "# os.environ['OPENAI_API_KEY'] = \"\"\n",
    "# GPT 4\n",
    "# os.environ['API_URL'] = \"\"\n",
    "# os.environ['OPENAI_API_KEY'] = \"\"\n",
    "\n",
    "root_directory = ''  # Assuming current directory, adjust path if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_set(root_directory):\n",
    "    json_dict = {}\n",
    "    # List of all subfolders and their files\n",
    "    subfolders_files = [(dp, filenames) for dp, _, filenames in os.walk(root_directory)]\n",
    "    # Dictionary comprehension to pick only the first JSON from each subfolder\n",
    "    json_dict = {os.path.basename(dp): os.path.join(dp, filenames[0]) for dp, filenames in subfolders_files if any(fn.endswith('.json') for fn in filenames)}\n",
    "\n",
    "    return json_dict\n",
    "\n",
    "json_dict = get_val_set(root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_25 = 0\n",
    "acc_50 = 0\n",
    "acc_25_unique = 0\n",
    "acc_50_unique = 0\n",
    "acc_25_multiple = 0\n",
    "acc_50_multiple = 0\n",
    "list_iou = []\n",
    "total_object = 0\n",
    "total_unique_object = 0\n",
    "total_multiple_object = 0\n",
    "session_id_list = []\n",
    "acc_25_top2_hit = 0\n",
    "acc_25_top3_hit = 0\n",
    "acc_25_top5_hit =0\n",
    "acc_25_all_hit = 0\n",
    "acc_25_top2_hit_unique = 0\n",
    "acc_25_top2_hit_multiple = 0\n",
    "acc_25_top3_hit_unique = 0\n",
    "acc_25_top3_hit_multiple = 0\n",
    "acc_25_top5_hit_unique = 0\n",
    "acc_25_top5_hit_multiple = 0\n",
    "acc_25_all_hit_unique = 0\n",
    "acc_25_all_hit_multiple = 0\n",
    "\n",
    "\n",
    "result_dict ={\n",
    "    'scene_name': list(),\n",
    "    'description': list(),\n",
    "    'centroid_list': list(),\n",
    "    'extent_list': list(),\n",
    "    'similarity_mean_list_list': list(),\n",
    "    'ground truth': list()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_description(agent, scene_name, description, corners_original, is_unique, object_id, query_rank_id, center_original, extents_original):  \n",
    "    MAX_RETRIES = 3\n",
    "    for retry in range(MAX_RETRIES):\n",
    "        try:\n",
    "            print(f\"Created new session for scene {scene_name}........................................................\")\n",
    "            new_session = Session.create_for_scene(scene_name)  \n",
    "            unique_id = str(uuid.uuid4())\n",
    "            new_session.session_id = f\"{scene_name}-{object_id}-{query_rank_id}-{unique_id}\" \n",
    "            new_session.working_scene_name = scene_name\n",
    "            new_session.grounding_query = description\n",
    "            new_session.ground_truth = [center_original, extents_original]\n",
    "            print(description)  \n",
    "            generator = agent.act(  \n",
    "                NO_VISUAL_FEEDBACK_SYSTEM_PROMPT,  \n",
    "                description,  \n",
    "                0.9,\n",
    "                1,\n",
    "                scene_name,\n",
    "                new_session  \n",
    "            )  \n",
    "            for chat_history_for_display, chat_counter, get_status_code, session, grounding_result_mesh_path in generator:  \n",
    "                pass  \n",
    "            prediction = session.candidate[str(session.chosen_candidate_id)]\n",
    "            center = prediction['centroid']  \n",
    "            extent = prediction['extent']  \n",
    "            prediction = construct_bbox_corners(center, extent)\n",
    "            iou3d_top_1 = box3d_iou(np.array(corners_original), prediction)\n",
    "            # we want to calculate top 3 iou from top_5_objects2scores and to make top_5_objects2scores ordered by the value\n",
    "            top_5_objects2scores = session.top_5_objects2scores\n",
    "            ranked_top_5_objects2scores = OrderedDict(sorted(top_5_objects2scores.items(), key=lambda item: item[1], reverse=True))\n",
    "            # top3 hit by looping over ranked_top_5_objects2scores and caluclate the iou\n",
    "            top2_hit_list = []\n",
    "            top3_hit_list = []\n",
    "            top5_hit_list = []\n",
    "            for index, (object_id, score) in enumerate(ranked_top_5_objects2scores.items()):\n",
    "                cur_candidate = session.candidate[str(object_id)]\n",
    "                cur_center = cur_candidate['centroid']  \n",
    "                cur_extent = cur_candidate['extent'] \n",
    "                cur_prediction = construct_bbox_corners(cur_center, cur_extent)\n",
    "                iou3d_top = box3d_iou(np.array(corners_original), cur_prediction)\n",
    "                if index < 2:\n",
    "                    top2_hit_list.append(iou3d_top)\n",
    "                if index < 3:\n",
    "                    top3_hit_list.append(iou3d_top)\n",
    "                top5_hit_list.append(iou3d_top)\n",
    "            \n",
    "            top2_hit = max(top2_hit_list)\n",
    "            top3_hit = max(top3_hit_list)\n",
    "            top5_hit = max(top5_hit_list)\n",
    "            \n",
    "            all_hit_list = []\n",
    "            \n",
    "            for _, candidate_mem in session.candidate.items():\n",
    "                center_candidate = candidate_mem['centroid']  \n",
    "                extent_candidate = candidate_mem['extent']  \n",
    "                prediction_candidate = construct_bbox_corners(center_candidate, extent_candidate)\n",
    "                iou3d_candidate = box3d_iou(np.array(corners_original), prediction_candidate)\n",
    "                all_hit_list.append(iou3d_candidate)\n",
    "            \n",
    "            all_hit = max(all_hit_list)\n",
    "            print(\"new session being saved........................................................\")\n",
    "            new_session.save(\"/workspace/chat-with-nerf-dev/chat-with-nerf/session_output_lerf_14_with_gpt_4_final\")\n",
    "            return iou3d_top_1, top2_hit, top3_hit, top5_hit, all_hit, session.session_id, session, is_unique\n",
    "        except Exception as exp:\n",
    "            if retry < MAX_RETRIES - 1:  # If it's not the last retry\n",
    "                print(f\"Attempt {retry + 1} failed. Retrying... Error is {exp}\")\n",
    "                continue\n",
    "            else:  # On the last retry, print the exception and return a message\n",
    "                print(exp)\n",
    "                # return f\"Failed after {MAX_RETRIES} attempts.\", None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (scene_name, json_path) in enumerate(json_dict.items()):\n",
    "    if scene_name == 'scene0169_00' or scene_name == 'scene0412_00':\n",
    "        print(f\"Processing scene {i+1}/{len(json_dict)}: {scene_name}\")\n",
    "        preprocessed_data = []\n",
    "        scene_path = json_dict[scene_name]\n",
    "        with open(scene_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        furnitures = data['objects']\n",
    "        agent = Agent(scene_name=scene_name)\n",
    "        agent.API_URL = os.environ['API_URL']\n",
    "        agent.OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "        for furniture in furnitures:\n",
    "            bbox = furniture['bbox']\n",
    "            center_original, extents_original = bbox[:3], bbox[3:6]\n",
    "            corners_original = construct_bbox_corners(center_original, extents_original)\n",
    "            label = furniture['label']\n",
    "            is_unique = is_label_unique(furnitures, label)\n",
    "            \n",
    "            if is_unique:\n",
    "                total_unique_object += len(furniture['description'])\n",
    "            else:\n",
    "                total_multiple_object += len(furniture['description'])\n",
    "            \n",
    "            for idx, description in enumerate(furniture['description']):\n",
    "                total_object += 1\n",
    "                preprocessed_data.append((agent, scene_name, description, corners_original, is_unique, label, idx, center_original, extents_original))\n",
    "        results = Parallel(n_jobs=15, backend='threading')(delayed(process_description)(*data) for data in tqdm(preprocessed_data, desc=\"Processing descriptions\"))\n",
    "        results_list.append(results)\n",
    "        del agent\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for results in results_list:\n",
    "    for result in results:\n",
    "        if result is None:\n",
    "            continue\n",
    "\n",
    "        iou3d, top2_hit, top3_hit, top5_hit, all_hit, session_id, session, is_unique = result\n",
    "    \n",
    "        if iou3d:\n",
    "            if iou3d > 0.25:  \n",
    "                acc_25 += 1\n",
    "                if is_unique:  \n",
    "                    acc_25_unique += 1  \n",
    "                else:\n",
    "                    acc_25_multiple += 1  \n",
    "            if iou3d > 0.5:\n",
    "                acc_50 += 1  \n",
    "                if is_unique:  \n",
    "                    acc_50_unique += 1  \n",
    "                else:  \n",
    "                    acc_50_multiple += 1\n",
    "        else:\n",
    "            iou3d = 0\n",
    "            sessionid = 'none'\n",
    "            \n",
    "        if top2_hit:\n",
    "            if top2_hit > 0.25:\n",
    "                acc_25_top2_hit += 1\n",
    "                if is_unique:\n",
    "                    acc_25_top2_hit_unique += 1\n",
    "                else:\n",
    "                    acc_25_top2_hit_multiple += 1\n",
    "    \n",
    "        if top3_hit:\n",
    "            if top3_hit > 0.25:\n",
    "                acc_25_top3_hit += 1\n",
    "                if is_unique:\n",
    "                    acc_25_top3_hit_unique += 1\n",
    "                else:\n",
    "                    acc_25_top3_hit_multiple += 1\n",
    "        \n",
    "        if top5_hit:\n",
    "            if top5_hit > 0.25:\n",
    "                acc_25_top5_hit += 1\n",
    "                if is_unique:\n",
    "                    acc_25_top5_hit_unique += 1\n",
    "                else:\n",
    "                    acc_25_top5_hit_multiple += 1\n",
    "                    \n",
    "        if all_hit:\n",
    "            if all_hit > 0.25:\n",
    "                acc_25_all_hit += 1\n",
    "                if is_unique:\n",
    "                    acc_25_all_hit_unique += 1\n",
    "                else:\n",
    "                    acc_25_all_hit_multiple += 1\n",
    "                    \n",
    "                    \n",
    "        list_iou.append(iou3d)\n",
    "        session_id_list.append(session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"acc_25 =\", acc_25)\n",
    "print(\"acc_50 =\", acc_50)\n",
    "print(\"acc_25_unique =\", acc_25_unique)\n",
    "print(\"acc_50_unique =\", acc_50_unique)\n",
    "print(\"acc_25_multiple =\", acc_25_multiple)\n",
    "print(\"acc_50_multiple =\", acc_50_multiple)\n",
    "print(\"acc_25_top2_hit =\", acc_25_top2_hit)\n",
    "print(\"acc_25_top3_hit =\", acc_25_top3_hit)\n",
    "print(\"acc_25_top5_hit =\", acc_25_top5_hit)\n",
    "print(\"acc_25_all_hit =\", acc_25_all_hit)\n",
    "print('total_object: ', total_object)\n",
    "print('total_unique_object: ', total_unique_object)\n",
    "print('total_multiple_object: ', total_multiple_object)\n",
    "print(\"acc_25_top2_hit_unique: \", acc_25_top2_hit_unique)\n",
    "print(\"acc_25_top2_hit_multiple: \", acc_25_top2_hit_multiple)\n",
    "print(\"acc_25_top3_hit_unique: \", acc_25_top3_hit_unique)\n",
    "print(\"acc_25_top3_hit_multiple: \", acc_25_top3_hit_multiple)\n",
    "print(\"acc_25_top5_hit_unique: \", acc_25_top5_hit_unique)   \n",
    "print(\"acc_25_top5_hit_multiple: \", acc_25_top5_hit_multiple)\n",
    "print(\"acc_25_all_hit_unique: \", acc_25_all_hit_unique)\n",
    "print(\"acc_25_all_hit_multiple: \", acc_25_all_hit_multiple)\n",
    "print(\"list_iou =\", list_iou)\n",
    "print(\"total_object =\", total_object)\n",
    "print(\"session_id_list =\", session_id_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
