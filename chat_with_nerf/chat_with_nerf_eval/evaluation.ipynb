{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "\u001b[32;20m[2023-09-08 15:45:58,575] INFO torch.distributed.nn.jit.instantiator [<module>] [instantiator.py:21] - Created a temporary directory at /tmp/tmp5xgj7ho5\u001b[0m\n",
      "\u001b[32;20m[2023-09-08 15:45:58,576] INFO torch.distributed.nn.jit.instantiator [_write] [instantiator.py:76] - Writing /tmp/tmp5xgj7ho5/_remote_module_non_scriptable.py\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chat_with_nerf.chat.agent import Agent \n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from chat_with_nerf.chat.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = '/workspace/chat-with-nerf-eval/data/scanrefer_val'  # Assuming current directory, adjust path if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box3d_min_max(corner):\n",
    "    ''' Compute min and max coordinates for 3D bounding box\n",
    "        Note: only for axis-aligned bounding boxes\n",
    "\n",
    "    Input:\n",
    "        corners: numpy array (8,3), assume up direction is Z (batch of N samples)\n",
    "    Output:\n",
    "        box_min_max: an array for min and max coordinates of 3D bounding box IoU\n",
    "\n",
    "    '''\n",
    "\n",
    "    min_coord = corner.min(axis=0)\n",
    "    max_coord = corner.max(axis=0)\n",
    "    x_min, x_max = min_coord[0], max_coord[0]\n",
    "    y_min, y_max = min_coord[1], max_coord[1]\n",
    "    z_min, z_max = min_coord[2], max_coord[2]\n",
    "    \n",
    "    return x_min, x_max, y_min, y_max, z_min, z_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box3d_iou(corners1, corners2):\n",
    "    ''' Compute 3D bounding box IoU.\n",
    "\n",
    "    Input:\n",
    "        corners1: numpy array (8,3), assume up direction is Z\n",
    "        corners2: numpy array (8,3), assume up direction is Z\n",
    "    Output:\n",
    "        iou: 3D bounding box IoU\n",
    "\n",
    "    '''\n",
    "    # # corner points are in counter clockwise order\n",
    "    # rect1 = [(corners1[i,0], corners1[i,2]) for i in range(3,-1,-1)]\n",
    "    # rect2 = [(corners2[i,0], corners2[i,2]) for i in range(3,-1,-1)] \n",
    "    # area1 = poly_area(np.array(rect1)[:,0], np.array(rect1)[:,1])\n",
    "    # area2 = poly_area(np.array(rect2)[:,0], np.array(rect2)[:,1])\n",
    "    # inter, inter_area = convex_hull_intersection(rect1, rect2)\n",
    "    # iou_2d = inter_area/(area1+area2-inter_area)\n",
    "    # ymax = min(corners1[0,1], corners2[0,1])\n",
    "    # ymin = max(corners1[4,1], corners2[4,1])\n",
    "    # inter_vol = inter_area * max(0.0, ymax-ymin)\n",
    "    # vol1 = box3d_vol(corners1)\n",
    "    # vol2 = box3d_vol(corners2)\n",
    "    # iou = inter_vol / (vol1 + vol2 - inter_vol)\n",
    "    # return iou, iou_2d\n",
    "\n",
    "    x_min_1, x_max_1, y_min_1, y_max_1, z_min_1, z_max_1 = get_box3d_min_max(corners1)\n",
    "    x_min_2, x_max_2, y_min_2, y_max_2, z_min_2, z_max_2 = get_box3d_min_max(corners2)\n",
    "    xA = np.maximum(x_min_1, x_min_2)\n",
    "    yA = np.maximum(y_min_1, y_min_2)\n",
    "    zA = np.maximum(z_min_1, z_min_2)\n",
    "    xB = np.minimum(x_max_1, x_max_2)\n",
    "    yB = np.minimum(y_max_1, y_max_2)\n",
    "    zB = np.minimum(z_max_1, z_max_2)\n",
    "    inter_vol = np.maximum((xB - xA), 0) * np.maximum((yB - yA), 0) * np.maximum((zB - zA), 0)\n",
    "    box_vol_1 = (x_max_1 - x_min_1) * (y_max_1 - y_min_1) * (z_max_1 - z_min_1)\n",
    "    box_vol_2 = (x_max_2 - x_min_2) * (y_max_2 - y_min_2) * (z_max_2 - z_min_2)\n",
    "    iou = inter_vol / (box_vol_1 + box_vol_2 - inter_vol + 1e-8)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_set():\n",
    "    json_dict = {}\n",
    "    # List of all subfolders and their files\n",
    "    subfolders_files = [(dp, filenames) for dp, _, filenames in os.walk(root_directory)]\n",
    "\n",
    "    # Dictionary comprehension to pick only the first JSON from each subfolder\n",
    "    json_dict = {os.path.basename(dp): os.path.join(dp, filenames[0]) for dp, filenames in subfolders_files if any(fn.endswith('.json') for fn in filenames)}\n",
    "\n",
    "    print(json_dict)\n",
    "    return json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dict = get_val_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;20m[2023-09-07 04:25:36,336] INFO chat_with_nerf [initialize_model_no_gpt_context] [model_context.py:54] - Search for all Scenes and Set the current Scene\u001b[0m\n",
      "\u001b[32;20m[2023-09-07 04:25:36,338] INFO chat_with_nerf [search_scenes] [model_context.py:89] - scene_path: /workspace/chat-with-nerf-dev/chat-with-nerf/data/scene0025_00/scene0025_00.yaml\u001b[0m\n",
      "\u001b[32;20m[2023-09-07 04:25:36,343] INFO root [create_model] [factory.py:154] - Loaded ViT-B-16 model config.\u001b[0m\n",
      "\u001b[32;20m[2023-09-07 04:25:37,659] INFO root [create_model] [factory.py:227] - Loading pretrained ViT-B-16 weights (laion2b_s34b_b88k).\u001b[0m\n",
      "scene0025_00\n",
      "/workspace/chat-with-nerf-eval/data/scanrefer_val/scene0025_00/72afcc45-a8b4-48b6-8224-783ad1d1ca95.json\n",
      "label:  monitor\n",
      "bbox:  [-0.30863550305366516, -1.6108747720718384, 0.9761558771133423, 0.4441679120063782, 0.42981481552124023, 0.5227721333503723]\n",
      "object_id:  1\n",
      "\u001b[32;20m[2023-09-07 04:25:50,828] INFO chat_with_nerf [create_for_scene] [session.py:42] - Creating a new session a6076721-313d-42b4-8a3d-2f12048eac0e with scene scene0025_00.\u001b[0m\n",
      "description:  ['there is a monitor sitting on the left side of a desk. the desk is smaller and curved of the two desks sitting back to back next to the window.  the monitor is more of a light gray, where the second one nearest the window is yellowed a little bit.', 'it is a white and black computer monitor shaped like a rectangle with a smaller, rectangular base. the monitor is the the right of another, taller computer monitor and in front of a desk chair.', 'this is an white and black monitor. it is behind an all black keyboard on a tan desk. it is close to an off white and black monitor of similar size.', 'the monitor is located on top of the desk, and to the left of the other monitor facing the chair. there is a keyboard in front of the monitor.', 'walking into the room, a large office desk is in the middle of the room. on the right side of the desk, there is a computer monitor on the table, specifically the one on the left side, closest to the door.']\n",
      "there is a monitor sitting on the left side of a desk. the desk is smaller and curved of the two desks sitting back to back next to the window.  the monitor is more of a light gray, where the second one nearest the window is yellowed a little bit.\n",
      "\u001b[38;20m[2023-09-07 04:25:50,831] DEBUG chat_with_nerf [call_visual_grounder_no_gpt] [visual_grounder.py:53] - Set Positive Words in Visual Grounder\u001b[0m\n",
      "\u001b[38;20m[2023-09-07 04:25:50,832] DEBUG chat_with_nerf [call_visual_grounder_no_gpt] [visual_grounder.py:54] - positive words: screen\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "scene_name = 'scene0025_00'\n",
    "scene_path = json_dict[scene_name]\n",
    "agent = Agent()\n",
    "print(scene_name)\n",
    "print(scene_path)\n",
    "with open(scene_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "print(\"label: \", data['objects'][0]['label'])\n",
    "print(\"bbox: \", data['objects'][0]['bbox'])\n",
    "print(\"object_id: \", data['objects'][0]['object_ids'])\n",
    "new_session = Session.create_for_scene(scene_name)\n",
    "print(\"description: \", data['objects'][0]['description'])\n",
    "for description in data['objects'][0]['description']:\n",
    "    print(description)\n",
    "    result = agent.act_no_gpt(\n",
    "        description,\n",
    "        scene_name,\n",
    "        new_session,\n",
    "    )\n",
    "    print(result)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;20m[2023-09-07 15:28:11,125] INFO chat_with_nerf [initialize_model_no_gpt_context] [model_context.py:54] - Search for all Scenes and Set the current Scene\u001b[0m\n",
      "\u001b[32;20m[2023-09-07 15:28:22,938] INFO chat_with_nerf [search_scenes] [model_context.py:89] - scene_path: /workspace/chat-with-nerf-dev/chat-with-nerf/data/scene0025_00/scene0025_00.yaml\u001b[0m\n",
      "\u001b[32;20m[2023-09-07 15:28:22,942] INFO chat_with_nerf [search_scenes] [model_context.py:89] - scene_path: /workspace/chat-with-nerf-dev/chat-with-nerf/data/home_1/home_1.yaml\u001b[0m\n",
      "\u001b[32;20m[2023-09-07 15:28:27,367] INFO root [create_model] [factory.py:154] - Loaded ViT-B-16 model config.\u001b[0m\n",
      "\u001b[32;20m[2023-09-07 15:28:28,706] INFO root [create_model] [factory.py:227] - Loading pretrained ViT-B-16 weights (laion2b_s34b_b88k).\u001b[0m\n",
      "\u001b[32;20m[2023-09-07 15:28:58,090] INFO chat_with_nerf [create_for_scene] [session.py:42] - Creating a new session bc7da60c-19e3-43fe-9e77-ae350ecb1d19 with scene home_1.\u001b[0m\n",
      "\u001b[38;20m[2023-09-07 15:29:02,947] DEBUG chat_with_nerf [call_visual_grounder_no_gpt] [visual_grounder.py:53] - Set Positive Words in Visual Grounder\u001b[0m\n",
      "\u001b[38;20m[2023-09-07 15:29:02,948] DEBUG chat_with_nerf [call_visual_grounder_no_gpt] [visual_grounder.py:54] - positive words: computer screen\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10 (ground_no_gpt_with_callback):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/chat-with-nerf-dev/chat-with-nerf/chat_with_nerf/chat/grounder.py\", line 83, in ground_no_gpt_with_callback\n",
      "    bbox = grond_no_gpt(session, ground_text, picture_taker)\n",
      "  File \"/workspace/chat-with-nerf-dev/chat-with-nerf/chat_with_nerf/chat/grounder.py\", line 71, in grond_no_gpt\n",
      "    bbox = VisualGrounder.call_visual_grounder_no_gpt(\n",
      "  File \"/workspace/chat-with-nerf-dev/chat-with-nerf/chat_with_nerf/visual_grounder/visual_grounder.py\", line 55, in call_visual_grounder_no_gpt\n",
      "    bbox = picture_taker.visual_ground_pipeline_no_gpt(\n",
      "  File \"/workspace/chat-with-nerf-dev/chat-with-nerf/chat_with_nerf/visual_grounder/picture_taker.py\", line 121, in visual_ground_pipeline_no_gpt\n",
      "    center, box_size = self.find_cluster(possibility_array)\n",
      "  File \"/workspace/chat-with-nerf-dev/chat-with-nerf/chat_with_nerf/visual_grounder/picture_taker.py\", line 144, in find_cluster\n",
      "    top_indices = np.argpartition(probability_over_all_points, -top_count)[\n",
      "  File \"<__array_function__ internals>\", line 200, in argpartition\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 871, in argpartition\n",
      "    return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 57, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "ValueError: kth(=-511) out of bounds (1)\n"
     ]
    }
   ],
   "source": [
    "scene_name = 'home_1'\n",
    "scene_path = '/workspace/chat-with-nerf-dev/chat-with-nerf/data/home_1'\n",
    "agent = Agent()\n",
    "new_session = Session.create_for_scene(scene_name)\n",
    "result = agent.act_no_gpt(\n",
    "    \"computer screen\",\n",
    "    scene_name,\n",
    "    new_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scene_id in scenes:\n",
    "    # swap to a new scene\n",
    "    llava_to_preserve = agent.model_context.captioner\n",
    "    agent.new_model_context = ModelContextManager.intialize_with_give_captioner(\n",
    "        llava_to_preserve\n",
    "    )\n",
    "\n",
    "    queries = get_text_queries(scene_id)\n",
    "    for query in queries:  # loop over each scene using joblib\n",
    "        new_session = Session.create_for_scene(scene_id)\n",
    "        while True:\n",
    "            (\n",
    "                chat_history_for_display,\n",
    "                chat_counter,\n",
    "                server_status_code,\n",
    "                session_state,\n",
    "                model_3d_grounding_result,\n",
    "            ) = agent.act(\n",
    "                system_msg=\"Hello, I am a chatbot\",\n",
    "                inputs=\"new text from user simulator\",\n",
    "                top_p=0.9,\n",
    "                temperature=0.1,\n",
    "                dropdown_scene=scene_id,\n",
    "                session=new_session,\n",
    "            )  # act() only returns if the control is given back to the user\n",
    "            \n",
    "   in executor.wait()  # wait for all queries for this scene to finish"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
